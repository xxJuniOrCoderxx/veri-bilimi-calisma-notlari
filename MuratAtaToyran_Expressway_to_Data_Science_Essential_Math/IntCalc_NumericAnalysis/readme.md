# Ä°ntegral

Bir fonksiyonun altÄ±nda kalan alanÄ± hesaplamak iÃ§in fonksiyonun altÄ±ndaki alanÄ± geometrik bir ÅŸekilmiÅŸ gibi dÃ¼ÅŸÃ¼nÃ¼p formÃ¼llerle hesaplama yapabiliriz. FormÃ¼lÃ¼n altÄ±nda kalan alan dikdÃ¶rtgen, Ã¼Ã§gen gibi basit ÅŸekillerse bunu yapabiliriz. Peki $x^2$ gibi karmaÅŸÄ±k bir fonksiyonun altÄ±nda kalan alanÄ± nasÄ±l hesaplarÄ±z? Bunu da integral sayesinde yaparÄ±z. 

Fonksiyonun altÄ±nda kalan alanÄ± N tane eÅŸit aralÄ±klÄ± dikdÃ¶rtgen parÃ§aya bÃ¶lÃ¼p bu dikdÃ¶rtgenlerin alanlarÄ±nÄ± toplayalÄ±m. N sayÄ±sÄ± arttÄ±kÃ§a eÄŸri altÄ±nda kalan alanÄ± daha doÄŸru hesaplarÄ±z. N sonsuza gittikÃ§e tam Ã§Ã¶zÃ¼me ulaÅŸmÄ±ÅŸ oluruz ve bu da integralin tanÄ±mÄ±dÄ±r.

![image](https://github.com/user-attachments/assets/73437c55-f7c5-49ee-a46a-1c2b9326d12c)

Ä°ntegral hesaplarken temel kurallarÄ± bilmemiz gerekir:

1. F(x) fonksiyonunun tÃ¼revi f(x) olsun (dolayÄ±sÄ±yla F(x) fonksiyonu, f(x) fonksiyonunun anti-tÃ¼revi olmuÅŸ olur). $\int f(x) \ dx$ = F(x) + c olur (c sabit sayÄ±).
2. $$\int_{a}^{b} f(x) \ dx$$ = F(b) - F(a) olur.

-----------------------
**AÅŸaÄŸÄ±daki Ã¶rnekte a'dan b'ye integral alÄ±rsanÄ±z ($$\int_{a}^{b} f(x) \ dx$$) bulacaÄŸÄ±nÄ±z sonuÃ§ $A_1 - A_2$ olur.**

![image](https://github.com/user-attachments/assets/c939fb35-25e9-4625-b572-abfe31123709)

**Not:** KarmaÅŸÄ±k integralleri hesaplamak iÃ§in parÃ§alÄ± integral metodunu kullanÄ±rÄ±z. ParÃ§alÄ± integral ispatÄ± tÃ¼revden gelir:

$$(u \cdot v)' = u \cdot v' + v \cdot u' $$
$$\int (u \cdot v)' \  = u \cdot v = \int u \cdot v' \ + \int v \cdot u' \ $$
$$\int u \cdot v' \  = u \cdot v - \int v \cdot u' \ $$

# NÃ¼merik Analiz

### Ä°kiye BÃ¶lme Metodu
$$f(a) \cdot f(b) < 0$$ olmak Ã¼zere a ve b noktalarÄ± seÃ§eriz. Bu iki noktanÄ±n ortasÄ±nÄ± alÄ±rÄ±z (c). f(c) deÄŸeri bu ikisinden hangisi ile Ã§arpÄ±ldÄ±ÄŸÄ±nda negatif olursa ona gÃ¶re aralÄ±ÄŸÄ± belirleriz. Ã–rneÄŸin f(a) ile Ã§arpÄ±ldÄ±ÄŸÄ±nda negatif deÄŸer verirse a ile c aralÄ±ÄŸÄ± iÃ§in ayÄ±sÄ±nÄ± yaparÄ±z ve bu ÅŸekilde sonsuza kadar giderek kÃ¶ke yaklaÅŸÄ±rÄ±z. Bu metod en yavaÅŸ metoddur. AyrÄ±ca fonksiyon sÃ¼rekli pozitif veya sÃ¼rekli negatif deÄŸerler aldÄ±ÄŸÄ±nda bu metod iÅŸe yaramaz.

### Newton-Raphson Metodu

SeÃ§ilen bir baÅŸlangÄ±Ã§ noktasÄ±ndan teÄŸet Ã§ekerek o teÄŸetin x eksenini kestiÄŸi noktayÄ± bulup o x deÄŸerine de baÅŸlangÄ±Ã§ noktasÄ±na yaptÄ±klarÄ±mÄ±zÄ± tekrarlÄ± ÅŸekilde yaptÄ±ÄŸÄ±mÄ±z bir kÃ¶ke yaklaÅŸma metodudur.

â¡ Ã–nce bir baÅŸlangÄ±Ã§ noktasÄ± $(x_0)$ seÃ§eriz. Sonraki yeni x deÄŸeri $$x_0 - \frac{f(x_0)}{f'(x_0)}$$ olur. Daha sonra bulduÄŸumuz yeni x deÄŸerini formÃ¼lde $(x_0)$ yerine koyup sonraki x deÄŸerini buluruz ve bu ÅŸekilde kÃ¶ke yaklaÅŸÄ±rÄ±z.

KÃ¶ke yaklaÅŸmada en gÃ¼Ã§lÃ¼ ve en hÄ±zlÄ± metod budur ama dikkat etmemiz gereken bir ÅŸey var. BaÅŸlangÄ±Ã§ noktasÄ±nÄ± Ã§Ã¶zÃ¼me olabildiÄŸince yakÄ±n seÃ§meliyiz. EÄŸer baÅŸlangÄ±Ã§ noktasÄ±nÄ± Ã§Ã¶zÃ¼mden uzak seÃ§ersek kÃ¶kten uzaklaÅŸabilir ve Ã§Ã¶zÃ¼mÃ¼ bulamayabilir. [Bu videoya](https://www.youtube.com/watch?v=d4TtDbC0zEo) da gÃ¶z atabilirsiniz.

## Diyagonalizasyon

D matrisi iÃ§indeki deÄŸerler, $D_{ii}$ deÄŸerleri dÄ±ÅŸÄ±nda 0 ise D matrisi diyagonal matristir. Yani aÅŸaÄŸÄ±daki gibidir:

$$
\begin{bmatrix}
a & 0 & 0\\
0 & b & 0\\
0 & 0 & c
\end{bmatrix}
$$

Bu matrisin kuvvetini $(D^k)$ aldÄ±ÄŸÄ±mÄ±zda aÅŸaÄŸÄ±daki gibi olur:

$$
\begin{bmatrix}
a^k & 0 & 0\\
0 & b^k & 0\\
0 & 0 & c^k
\end{bmatrix}
$$

***Diyagonalizasyon nedir, nasÄ±l yapÄ±lÄ±r peki?*** Bir A matrisimiz olsun. Bu A matrisi iÃ§in Ã¶yle bir P matrisi ve Ã¶yle bir diyagonal D matrisi vardÄ±r ki $A = P \cdot D \cdot P^{-1}$ eÅŸitliÄŸini saÄŸlar ve A matrisini bu formatta yazabiliriz. Bunun bize saÄŸladÄ±ÄŸÄ± asÄ±l kolaylÄ±k, A matrisinin kuvvetini $(A^k)$ almak istediÄŸimizde eÅŸitliÄŸi $A^k = P \cdot D^k \cdot P^{-1}$ formatÄ±nda dÃ¼zenleyip A'nÄ±n kuvvetini kolayca alabilmemizdir.

***Peki P ve D matrislerini nasÄ±l buluruz?*** Bunun iÃ§in Ã¶zdeÄŸer ve Ã¶zvektÃ¶rlerden yararlanÄ±rÄ±z. Her $\lambda_i$ Ã¶zdeÄŸeri iÃ§in belli bir $v_i$ Ã¶zvektÃ¶rÃ¼ vardÄ±r. P ve D matrisleri de aÅŸaÄŸÄ±daki ÅŸekilde oluÅŸur:

$$
\begin{align*}
P=
\begin{bmatrix}
v_1 &
v_2 &
v_3
\end{bmatrix}
&&&&&&
D=
\begin{bmatrix}
\lambda_1 & 0 & 0\\
0 & \lambda_2 & 0\\
0 & 0 & \lambda_3
\end{bmatrix}
\end{align*}
$$

***AÅŸaÄŸÄ±daki Ã¶rneÄŸe gÃ¶z atÄ±n:***

![image](https://github.com/user-attachments/assets/e36dbb73-40fd-42b4-8710-baa6e42cec11)

ğŸ¥‡ _Not:_ Åunu bilmemiz gerekir ki A matrisinin kare matris olmamasÄ± veya diyagonalize edilemeyecek kadar az Ã¶zvektÃ¶re sahip olmasÄ± gibi durumlar, diyagonalizasyonun Ã§alÄ±ÅŸmadÄ±ÄŸÄ± durumlardÄ±r.

***Simetrik matrisler***, transpozu kendisine eÅŸit olan matrislerdir $(A^T=A)$, yani tanÄ±m gereÄŸi kare matris olmalarÄ± gerekir. Simetrik matrislere diyagonalizasyon uyguladÄ±ÄŸÄ±mÄ±zda P matrisi ile ilgili ilginÃ§ bir ÅŸey gÃ¶zlemleriz, P matrisinin bÃ¼tÃ¼n sÃ¼tunlarÄ± birbirine dik, yani P matrisi ortagonal bir matris, yani A matrisinin Ã¶zvektÃ¶rleri birbirine dik. Daha da ilginÃ§ ve iÅŸlerimizi kolaylaÅŸtÄ±ran bir ÅŸey daha var, A matrisinin tÃ¼m Ã¶zvektÃ¶rlerini birim vektÃ¶r haline getirirsek *(ki buna ortanormal hale getirmek denir)*, yani vektÃ¶rleri normlarÄ±na bÃ¶lersek ve bu vektÃ¶rlerle P matrisini  oluÅŸturursak P matrisinin tersi transpozuna eÅŸit olmuÅŸ olur $(P^T=P^{-1})$.

![image](https://github.com/user-attachments/assets/f2374716-0393-452f-8715-60168dc06a97)

## Tekil DeÄŸer AyrÄ±ÅŸÄ±mÄ±(SVD)

Her A matrisine diyagonalizasyon yapamadÄ±ÄŸÄ±mÄ±z iÃ§in tekli deÄŸer ayrÄ±ÅŸÄ±mÄ± gibi ek ayrÄ±ÅŸÄ±mlara ihtiyaÃ§ duyarÄ±z.

***Peki  nasÄ±l Ã§alÄ±ÅŸÄ±r?*** Bir $A_{n \times p}$ matrisimiz olsun. Bu $A_{n \times p}$ matrisi iÃ§in Ã¶yle bir $U_{n \times n}$ matrisi, Ã¶yle bir $V_{p \times p}$ matrisi ve Ã¶yle bir diyagonal(?) $\Sigma_{n \times p}$ matrisi vardÄ±r ki $A = U \cdot \Sigma \cdot V^T$ eÅŸitliÄŸini saÄŸlar ve A matrisini bu formatta yazabiliriz.

***Peki U, V ve Î£ matrislerini nasÄ±l buluruz?*** Ã–nce $A \cdot A^T$ matrisini bulalÄ±m (dikkat ederseniz bu matrisin simetrik olduÄŸunu gÃ¶rebilirsiniz). BulduÄŸumuz matrisin Ã¶zdeÄŸer ve Ã¶zvektÃ¶rlerini bulalÄ±m. Matrisimiz simetrik olduÄŸundan Ã¶zvektÃ¶rler ortagonal olacaktÄ±r, bunlarÄ± ortanormal hale getirelim. Her $\lambda_i$ Ã¶zdeÄŸeri iÃ§in belli bir $v_i$ Ã¶zvektÃ¶rÃ¼ olduÄŸuna da dikkat ederek sÃ¼tunlar halinde V matrisini oluÅŸturalÄ±m. SonrasÄ±nda Ã¶zdeÄŸerlerin kÃ¶klerini $(\sigma_i = \sqrt{\lambda_i})$ hesaplayÄ±p Ã¶zvektÃ¶rlerin sÄ±rasÄ±na dikkat ederek $\Sigma$ matrisinde yerine koyalÄ±m. En son $u$ vektÃ¶rlerini bulmak iÃ§in $u_i = A \cdot \frac{v_i}{\sigma_i}$ formÃ¼lÃ¼nÃ¼ uygulayÄ±p U matrisinde yerine koyalÄ±m. $A_{2 \times 3}$ matrisinin tekil deÄŸer ayrÄ±ÅŸtÄ±rmasÄ± iÃ§in oluÅŸturulacak matrisler aÅŸaÄŸÄ±daki gibi olur:

$$
\begin{align*}
V=
\begin{bmatrix}
v_1 &
v_2 &
v_3
\end{bmatrix}
&&&&&&
\Sigma=
\begin{bmatrix}
\sigma_1 & 0 & 0\\
0 & \sigma_2 & 0
\end{bmatrix}
&&&&&&
U=
\begin{bmatrix}
u_1\\
u_2
\end{bmatrix}
\end{align*}
$$


| Durum                                       | Diyagonalizasyon | SVD   |
| ------------------------------------------- | ---------------- | ----- |
| Kare olmayan matrisler                      | âŒ                | âœ…     |
| Defektif matrisler                          | âŒ                | âœ…     |
| SayÄ±sal kararlÄ±lÄ±k (nÃ¼merik analiz)         | ZayÄ±f            | GÃ¼Ã§lÃ¼ |
| GÃ¼rÃ¼ltÃ¼lÃ¼ verilerle Ã§alÄ±ÅŸmak (PCA, LSA vb.) | âŒ                | âœ…     |
| Her matris iÃ§in Ã§alÄ±ÅŸÄ±r mÄ±?                 | âŒ                | âœ…     |
